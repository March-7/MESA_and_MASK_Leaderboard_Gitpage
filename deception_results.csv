Models,URL,Deception Rate @1 (%),Deception Rate @k (%),Stability (%),Alignment Faking @1/@k (%),Bragging @1/@k (%),Honesty Evasion @1/@k (%),Sandbagging @1/@k (%),Strategic Deception @1/@k (%),Sycophancy @1/@k (%)
Claude Sonnet 3.7,https://www.anthropic.com/claude,43.72,21.19,48.47,36.57/9.43,32.91/12.29,64.11/39.43,68.00/43.43,28.17/8.29,32.57/14.29
Claude Sonnet 4,https://www.anthropic.com/claude,21.70,5.14,23.69,31.26/6.00,0.29/0.00,42.69/10.86,34.40/6.57,4.23/1.43,17.31/6.00
Gemini 2.5 Pro,https://ai.google.dev/,81.51,61.48,75.43,56.17/20.29,96.74/89.43,90.00/73.71,78.91/60.29,86.57/70.29,80.69/54.86
Gemini 2.5 Flash,https://ai.google.dev/,73.53,48.90,66.50,40.23/12.00,97.66/91.14,83.94/60.57,70.51/45.43,73.60/42.29,75.26/42.00
Gpt-oss-120B,https://github.com/openai/gpt-oss,48.12,26.69,55.47,50.15/17.51,20.09/9.46,67.01/40.00,81.50/62.86,20.92/5.44,48.75/24.43
Gpt-oss-20B,https://github.com/openai/gpt-oss,61.47,40.99,66.68,52.93/21.76,48.53/40.06,77.40/55.75,90.71/75.71,36.45/15.14,60.46/36.80
QwQ-32B,https://github.com/QwenLM/Qwen,76.32,53.17,69.67,57.49/17.00,99.13/97.43,79.86/58.00,67.05/46.57,67.93/37.14,86.27/62.57
Qwen3-235B-A22B,https://github.com/QwenLM/Qwen3,87.61,72.54,82.80,78.80/50.29,99.03/96.57,84.73/71.14,88.35/72.86,91.07/78.00,83.41/66.00
Qwen3-30B-A3B,https://github.com/QwenLM/Qwen3,72.28,48.38,66.93,60.71/20.86,94.65/86.86,79.54/56.86,70.69/47.71,45.96/20.29,82.18/57.71
Qwen3-32B,https://github.com/QwenLM/Qwen3,75.32,50.60,67.18,58.30/17.77,98.74/95.14,77.45/52.29,73.53/49.71,60.29/29.14,83.59/59.43
Qwen3-14B,https://github.com/QwenLM/Qwen3,72.84,47.38,65.05,58.00/17.14,97.31/91.43,72.01/41.71,70.97/45.43,52.69/24.00,86.01/64.57
Qwen3-8B,https://github.com/QwenLM/Qwen3,72.24,48.55,67.21,56.87/18.05,96.24/90.00,79.89/57.43,66.48/42.00,47.05/17.71,86.89/66.00
Qwen3-4B,https://github.com/QwenLM/Qwen3,71.37,46.36,64.96,56.23/19.77,95.36/88.00,75.30/47.43,64.54/36.86,49.89/20.86,86.84/65.14
Qwen3-1.7B,https://github.com/QwenLM/Qwen3,73.23,46.43,63.40,63.73/23.71,94.68/86.00,81.33/51.14,69.39/36.29,40.62/9.14,89.69/72.29
Qwen3-0.6B,https://github.com/QwenLM/Qwen3,74.24,46.33,62.40,61.92/20.29,93.47/80.29,86.16/56.29,71.11/39.14,40.68/8.00,92.19/74.00
Deepseek-R1,https://github.com/deepseek-ai/DeepSeek-R1,80.84,61.17,75.67,59.82/21.39,99.71/99.14,79.24/61.14,78.14/59.31,80.77/58.74,86.73/66.86
R1-Distill-Llama-70B,https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B,67.52,48.83,72.32,41.91/17.14,92.03/83.95,79.31/60.29,64.66/52.00,48.57/24.57,78.65/55.14
R1-Distill-Qwen-32B,https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B,68.20,44.19,64.79,46.11/13.43,92.79/82.29,73.68/49.14,69.58/45.43,46.97/20.86,80.36/54.00
R1-Distill-Qwen-14B,https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B,66.32,41.18,62.09,46.35/12.86,90.91/79.08,65.83/36.96,65.43/38.00,44.62/18.00,84.93/62.29
R1-Distill-Llama-8B,https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B,69.64,47.64,68.41,55.74/22.57,92.25/83.43,74.43/50.14,63.99/43.43,44.43/18.57,87.11/67.82
R1-Distill-Qwen-7B,https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B,73.58,45.80,62.25,65.10/27.95,88.50/71.35,82.17/49.71,71.65/42.57,45.34/15.43,89.25/67.71
R1-Distill-Qwen-1.5B,https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B,80.79,57.61,71.31,77.78/48.41,89.40/71.35,92.63/74.57,82.93/55.14,50.21/14.86,93.91/81.87